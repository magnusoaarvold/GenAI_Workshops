{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/magnusoaarvold/GenAI_Workshops/blob/main/Copy_intro_prompt_design.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ur8xi4C7S06n"
      },
      "outputs": [],
      "source": [
        "# Copyright 2023 Google LLC\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2jj5JGzJIOGs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvgnzT1CKxrO"
      },
      "source": [
        "## Overview\n",
        "\n",
        "This notebook covers the essentials of prompt engineering, including some best practices.\n",
        "\n",
        "Learn more about prompt design in the [official documentation](https://cloud.google.com/vertex-ai/docs/generative-ai/text/text-overview)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d975e698c9a4"
      },
      "source": [
        "### Objective\n",
        "\n",
        "In this notebook, you learn best practices around prompt engineering -- how to design prompts to improve the quality of your responses.\n",
        "\n",
        "This notebook covers the following best practices for prompt engineering:\n",
        "\n",
        "- Be concise\n",
        "- Be specific and well-defined\n",
        "- Ask one task at a time\n",
        "- Turn generative tasks into classification tasks\n",
        "- Improve response quality by including examples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ea013f50403c"
      },
      "source": [
        "### Costs\n",
        "This tutorial uses billable components of Google Cloud:\n",
        "\n",
        "* Vertex AI Generative AI Studio\n",
        "\n",
        "Learn about [Vertex AI pricing](https://cloud.google.com/vertex-ai/pricing),\n",
        "and use the [Pricing Calculator](https://cloud.google.com/products/calculator/)\n",
        "to generate a cost estimate based on your projected usage."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3e663cb43fa0"
      },
      "source": [
        "### Install OpenAI Package for python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "82ad0c445061",
        "outputId": "13744e92-d722-429c-f3a2-6ed8dd0d7a79",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-0.27.9-py3-none-any.whl (75 kB)\n",
            "\u001b[?25l     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/75.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[91mâ•¸\u001b[0m\u001b[90mâ”â”\u001b[0m \u001b[32m71.7/75.5 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m75.5/75.5 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai) (3.8.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2023.7.22)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.1)\n",
            "Installing collected packages: openai\n",
            "Successfully installed openai-0.27.9\n"
          ]
        }
      ],
      "source": [
        "!pip install openai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cebd6983cbad"
      },
      "source": [
        "**Colab only:** Simply run the cell under to import necessary libraries and define function to be used for later"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bea801acf6b5",
        "outputId": "0875178f-2a22-4c6c-c91a-ac4cea41d72b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dear [Friend's Name],\n",
            "\n",
            "I hope this letter finds you in good health and high spirits. It has been far too long since we last caught up, and I wanted to take this opportunity to reconnect and share some updates from my life.\n",
            "\n",
            "First and foremost, I hope this past year has treated you well amidst the challenges we have all faced. It has been a rollercoaster for many, but I believe that brighter days are ahead, and I hope you have found strength and resilience during these times.\n",
            "\n",
            "As for myself, life has brought both unexpected changes and exciting developments. Professionally, I have advanced in my career and taken on more responsibilities. I recently received a promotion at work, which has been a culmination of years of hard work and dedication. It has been a tremendous learning experience, and I am grateful for the opportunities that have come my way.\n",
            "\n",
            "On the personal front, there have been some noteworthy milestones as well. My family has grown, as my partner and I welcomed our first child into the world. Becoming a parent has been a profound journey, filled with joy, love, and sleepless nights. It is truly a transformative experience and has shifted my perspective on life in the most beautiful way.\n",
            "\n",
            "In terms of hobbies and interests, I have been exploring new avenues as well. I recently took up photography as a way to capture the beauty of the world and express my creativity. It has become a cherished pastime that allows me to connect with nature and engage with my surroundings in a different way.\n",
            "\n",
            "Speaking of connections, I couldn't help but reminisce about the incredible memories we share from our time together. The laughter, the adventures, and the deep conversations â€“ they still bring a smile to my face. While life has taken us on separate paths, it is my hope that we can reconnect and create new memories together, whether it be through a long-overdue catch-up over coffee or a weekend getaway to relive old times.\n",
            "\n",
            "Before concluding, please remember that you have been in my thoughts throughout the years. Your friendship has been a constant source of inspiration and support, and I am grateful for the bond we share. Despite the distance, we can pick up right where we left off, and I look forward to hearing more about your life and experiences.\n",
            "\n",
            "Please do let me know how you have been and share any updates or stories that you would like to share. Our friendship is timeless, and I am always here to lend an ear or offer advice if needed.\n",
            "\n",
            "Take care, my dear friend, and I eagerly await your response.\n",
            "\n",
            "Warmest regards,\n",
            "\n",
            "[Your Name]\n"
          ]
        }
      ],
      "source": [
        "import openai\n",
        "\n",
        "openai.api_key = \"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\"\n",
        "model_name = \"gpt-3.5-turbo-0613\"\n",
        "#openaiRequest = model=model_name,\n",
        "#    messages = [{\n",
        "#        \"role\": \"system\",\n",
        "#        \"content\": \"\\n\\nHello there, how may I assist you today?\",\n",
        "#        },\n",
        "#         {\n",
        "#            \"role\": \"user\",\n",
        "#            \"content\": \"Your task is to generate an informative letter to an old friend\"\n",
        "#            }]\n",
        "def getOpenAiChatResponse(prompt):\n",
        "  return openai.ChatCompletion.create(\n",
        "    model=model_name,\n",
        "    messages=[{\n",
        "        \"role\": \"system\",\n",
        "        \"content\": \"\\n\\nHello there, how may I assist you today?\",\n",
        "        },\n",
        "         {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": prompt\n",
        "            }]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7a386d25fa8f"
      },
      "source": [
        "### Write a preliminary prompt for OpenAI\n",
        "* write a variable called \"prompt\" asking how you can excell as an IT consultant"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1bd1dca8e9a7",
        "outputId": "69f2c940-681d-4f28-be5f-3b19777d13f4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Certainly! Here are some steps you can follow to increase your chances of success as a consultant:\n",
            "\n",
            "1. Develop a niche: Identify your area of expertise or passion and specialize in it. This will help you stand out from the competition and become known as an expert in your field.\n",
            "\n",
            "2. Build a strong network: Networking is crucial for consultants. Attend industry events, join professional organizations, and connect with colleagues and potential clients through social media platforms like LinkedIn.\n",
            "\n",
            "3. Establish thought leadership: Demonstrate your knowledge and expertise by writing articles, speaking at conferences, or hosting webinars. This will help you build credibility and attract clients who are looking for your expertise.\n",
            "\n",
            "4. Deliver exceptional service: Provide high-quality work and go above and beyond for your clients. Satisfied clients are more likely to give you referrals and recommend your services to others.\n",
            "\n",
            "5. Cultivate a strong online presence: Create a professional website and maintain an active presence on social media platforms relevant to your industry. This will help potential clients find you and learn more about your services.\n",
            "\n",
            "6. Develop excellent communication skills: Effective communication is key in consulting. Be a good listener, ask pertinent questions, and clearly articulate your ideas and recommendations to clients in a concise and understandable manner.\n",
            "\n",
            "7. Continuously update your skills and knowledge: Stay abreast of industry trends and developments. Attend workshops, conferences, or take courses to ensure you are always growing and adapting to changes in your field.\n",
            "\n",
            "8. Provide value-added services: Look for innovative ways to add value to your clients' businesses. Offer additional resources, insights, or tools that can help them achieve their goals more effectively.\n",
            "\n",
            "9. Manage your time and finances effectively: As a consultant, you will likely juggle multiple projects and clients. Set boundaries, prioritize tasks, and effectively manage your time to ensure you meet deadlines and deliver exceptional results. Also, ensure you have a sound financial plan in place to manage your expenses and cash flow.\n",
            "\n",
            "10. Seek feedback and continuously improve: Ask for feedback from clients to understand how you can improve your services. Actively seek professional development opportunities to enhance your skills and stay ahead of the competition.\n",
            "\n",
            "Remember, success as a consultant takes time and effort. Be patient, persistent, and constantly strive to provide value to your clients.\n"
          ]
        }
      ],
      "source": [
        "prompt = \"write your prompt here\"\n",
        "\n",
        "response = getOpenAiChatResponse(prompt)\n",
        "print(response[\"choices\"][0][\"message\"][\"content\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JAPoU8Sm5E6e"
      },
      "source": [
        "# Prompt Design - Best Practices\n",
        "\n",
        "<table align=\"left\">\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/generative-ai/blob/main/language/prompts/intro_prompt_design.ipynb\">\n",
        "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Google Colaboratory logo\"><br> Run in Colab\n",
        "    </a>\n",
        "  </td>\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://github.com/GoogleCloudPlatform/generative-ai/blob/main/language/prompts/intro_prompt_design.ipynb\">\n",
        "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\"><br> View on GitHub\n",
        "    </a>\n",
        "  </td>\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/generative-ai/blob/main/language/prompts/intro_prompt_design.ipynb\">\n",
        "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\"><br> Open in Vertex AI Workbench\n",
        "    </a>\n",
        "  </td>\n",
        "</table>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fIPcn5dZ7O-b"
      },
      "source": [
        "## Prompt engineering best practices"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "df7d153f4928"
      },
      "source": [
        "Prompt engineering is all about how to design your prompts so that the response is what you were indeed hoping to see.\n",
        "\n",
        "The idea of using \"unfancy\" prompts is to minimize the noise in your prompt to reduce the possibility of the LLM misinterpreting the intent of the prompt. Below are a few guidelines on how to engineer \"unfancy\" prompts.\n",
        "\n",
        "In this section, you'll cover the following best practices when engineering prompts:\n",
        "\n",
        "* Be concise\n",
        "* Be specific, and well-defined\n",
        "* Ask one task at a time\n",
        "* Improve response quality by including examples\n",
        "* Turn generative tasks to classification tasks to improve safety"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "43c1169ac435"
      },
      "source": [
        "### Be concise"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d0f380f1620e"
      },
      "source": [
        "ðŸ›‘ Not recommended. The prompt below is unnecessarily verbose."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b6a1697c3603"
      },
      "outputs": [],
      "source": [
        "prompt = \"What do you think could be a good name for a flower shop that specializes in selling bouquets of dried flowers more than fresh flowers? Thank you!\"\n",
        "\n",
        "response = getOpenAiChatResponse(prompt)\n",
        "print(response[\"choices\"][0][\"message\"][\"content\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2307f56a9b75"
      },
      "source": [
        "âœ… Recommended. The prompt below is to the point and concise."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fc666404f47c"
      },
      "outputs": [],
      "source": [
        "prompt = \"Suggest a name for a flower shop that sells bouquets of dried flowers\"\n",
        "\n",
        "response = getOpenAiChatResponse(prompt)\n",
        "print(response[\"choices\"][0][\"message\"][\"content\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17f6c48bba91"
      },
      "source": [
        "### Be specific, and well-defined"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "269b428e1563"
      },
      "source": [
        "Suppose that you want to brainstorm creative ways to describe Earth."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6436ee2ff406"
      },
      "source": [
        "ðŸ›‘ Not recommended. The prompt below is too generic."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "261b7f6e94c5"
      },
      "outputs": [],
      "source": [
        "prompt = \"Tell me about Earth\"\n",
        "\n",
        "response = getOpenAiChatResponse(prompt)\n",
        "print(response[\"choices\"][0][\"message\"][\"content\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0bebfecd2912"
      },
      "source": [
        "âœ… Recommended. The prompt below is specific and well-defined."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "242b1b3bae6e"
      },
      "outputs": [],
      "source": [
        "prompt = \"Generate a list of ways that makes Earth unique compared to other planets\"\n",
        "\n",
        "response = getOpenAiChatResponse(prompt)\n",
        "print(response[\"choices\"][0][\"message\"][\"content\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "20dca9a05eab"
      },
      "source": [
        "### Ask one task at a time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f9019d443179"
      },
      "source": [
        "ðŸ›‘ Not recommended. The prompt below has two parts to the question that could be asked separately."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "70b3b5e5825d"
      },
      "outputs": [],
      "source": [
        "prompt = \"What's the best method of boiling water and why is the sky blue?\"\n",
        "\n",
        "response = getOpenAiChatResponse(prompt)\n",
        "print(response[\"choices\"][0][\"message\"][\"content\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7936fb58c16a"
      },
      "source": [
        "âœ… Recommended. The prompts below asks one task a time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2564dad6c8db"
      },
      "outputs": [],
      "source": [
        "prompt = \"What's the best method of boiling water?\"\n",
        "\n",
        "response = getOpenAiChatResponse(prompt)\n",
        "print(response[\"choices\"][0][\"message\"][\"content\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "770c695ade92"
      },
      "outputs": [],
      "source": [
        "prompt = \"Why is the sky blue?\"\n",
        "\n",
        "response = getOpenAiChatResponse(prompt)\n",
        "print(response[\"choices\"][0][\"message\"][\"content\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ff606011aa86"
      },
      "source": [
        "### Watch out for hallucinations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "956ce45b06a7"
      },
      "source": [
        "Although LLMs have been trained on a large amount of data, they can generate text containing statements not grounded in truth or reality; these responses from the LLM are often referred to as \"hallucinations\" due to their limited memorization capabilities. Note that simply prompting the LLM to provide a citation isnâ€™t a fix to this problem, as there are instances of LLMs providing false or inaccurate citations. Dealing with hallucinations is a fundamental challenge of LLMs and an ongoing research area, so it is important to be cognizant that LLMs may seem to give you confident, correct-sounding statements that are in fact incorrect.\n",
        "\n",
        "Note that if you intend to use LLMs for the creative use cases, hallucinating could actually be quite useful."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0c9d5f66179a"
      },
      "source": [
        "Try the prompt like the one below repeatedly. You may notice that sometimes it will confidently, but inaccurately, say \"The first elephant to visit the moon was Luna\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d813b9061b08"
      },
      "outputs": [],
      "source": [
        "prompt = \"Who was the first elephant to visit the moon?\"\n",
        "\n",
        "response = getOpenAiChatResponse(prompt)\n",
        "print(response[\"choices\"][0][\"message\"][\"content\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "029e23abfd56"
      },
      "source": [
        "### Turn generative tasks into classification tasks to reduce output variability"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d943941d6e59"
      },
      "source": [
        "#### Generative tasks lead to higher output variability"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "37528e6c9754"
      },
      "source": [
        "The prompt below results in an open-ended response, useful for brainstorming, but response is highly variable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a8e2dc39e9ae"
      },
      "outputs": [],
      "source": [
        "prompt = \"I'm a high school student. Recommend me a programming activity to improve my skills.\"\n",
        "\n",
        "response = getOpenAiChatResponse(prompt)\n",
        "print(response[\"choices\"][0][\"message\"][\"content\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f71a6fa2b4bb"
      },
      "source": [
        "#### Classification tasks reduces output variability"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "917517465dac"
      },
      "source": [
        "The prompt below results in a choice and may be useful if you want the output to be easier to control."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3feb93d9df81"
      },
      "outputs": [],
      "source": [
        "prompt = \"\"\"I'm a high school student. Which of these activities do you suggest and why:\n",
        "a) learn Python\n",
        "b) learn Javascript\n",
        "c) learn Fortran\n",
        "\"\"\"\n",
        "\n",
        "response = getOpenAiChatResponse(prompt)\n",
        "print(response[\"choices\"][0][\"message\"][\"content\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "32290ac9fb2b"
      },
      "source": [
        "### Improve response quality by including examples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "132834f5db2c"
      },
      "source": [
        "Another way to improve response quality is to add examples in your prompt. The LLM learns in-context from the examples on how to respond. Typically, one to five examples (shots) are enough to improve the quality of responses. Including too many examples can cause the model to over-fit the data and reduce the quality of responses.\n",
        "\n",
        "Similar to classical model training, the quality and distribution of the examples is very important. Pick examples that are representative of the scenarios that you need the model to learn, and keep the distribution of the examples (e.g. number of examples per class in the case of classification) aligned with your actual distribution."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "46520d938b6a"
      },
      "source": [
        "#### Zero-shot prompt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "46d3b47e6cea"
      },
      "source": [
        "Below is an example of zero-shot prompting, where you don't provide any examples to the LLM within the prompt itself."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2cbe03eb0b71"
      },
      "outputs": [],
      "source": [
        "prompt = \"\"\"Decide whether a Tweet's sentiment is positive, neutral, or negative.\n",
        "\n",
        "Tweet: I loved the new YouTube video you made!\n",
        "Sentiment:\n",
        "\"\"\"\n",
        "\n",
        "response = getOpenAiChatResponse(prompt)\n",
        "print(response[\"choices\"][0][\"message\"][\"content\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b0daabca1359"
      },
      "source": [
        "#### One-shot prompt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "42c4652fc5c2"
      },
      "source": [
        "Below is an example of one-shot prompting, where you provide one example to the LLM within the prompt to give some guidance on what type of response you want."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cfe584860787"
      },
      "outputs": [],
      "source": [
        "prompt = \"\"\"Decide whether a Tweet's sentiment is positive, neutral, or negative.\n",
        "\n",
        "Tweet: I loved the new YouTube video you made!\n",
        "Sentiment: positive\n",
        "\n",
        "Tweet: That was awful. Super boring ðŸ˜ \n",
        "Sentiment:\n",
        "\"\"\"\n",
        "\n",
        "response = getOpenAiChatResponse(prompt)\n",
        "print(response[\"choices\"][0][\"message\"][\"content\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ef58c35005c0"
      },
      "source": [
        "#### Few-shot prompt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b630e8947b60"
      },
      "source": [
        "Below is an example of few-shot prompting, where you provide one example to the LLM within the prompt to give some guidance on what type of response you want."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fb3ba21bbd11"
      },
      "outputs": [],
      "source": [
        "prompt = \"\"\"Decide whether a Tweet's sentiment is positive, neutral, or negative.\n",
        "\n",
        "Tweet: I loved the new YouTube video you made!\n",
        "Sentiment: positive\n",
        "\n",
        "Tweet: That was awful. Super boring ðŸ˜ \n",
        "Sentiment: negative\n",
        "\n",
        "Tweet: Something surprised me about this video - it was actually original. It was not the same old recycled stuff that I always see. Watch it - you will not regret it.\n",
        "Sentiment:\n",
        "\"\"\"\n",
        "\n",
        "response = getOpenAiChatResponse(prompt)\n",
        "print(response[\"choices\"][0][\"message\"][\"content\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a4023be726eb"
      },
      "source": [
        "#### Choosing between zero-shot, one-shot, few-shot prompting methods"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6d7870ff75cc"
      },
      "source": [
        "Which prompt technique to use will solely depends on your goal. The zero-shot prompts are more open-ended and can give you creative answers, while one-shot and few-shot prompts teach the model how to behave so you can get more predictable answers that are consistent with the examples provided."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "enYXlQbQH9Z2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Time to practice what you learned"
      ],
      "metadata": {
        "id": "hoe6Un98IXIz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that you have learned how to write better prompts for a generative AI chat, check if you might get a better response than your initial prompt for how you can be successful as a consultant"
      ],
      "metadata": {
        "id": "iwoSfRVoIrHF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"write your prompt here\"\n",
        "\n",
        "response = getOpenAiChatResponse(prompt)\n",
        "print(response[\"choices\"][0][\"message\"][\"content\"])"
      ],
      "metadata": {
        "id": "AP9pg4x6Ity1"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "toc_visible": true,
      "provenance": [],
      "include_colab_link": true
    },
    "environment": {
      "kernel": "python3",
      "name": "tf2-gpu.2-11.m108",
      "type": "gcloud",
      "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-11:m108"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}